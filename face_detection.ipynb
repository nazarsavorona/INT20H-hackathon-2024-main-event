{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/wiki_crop/'\n",
    "FACES_FOLDER = 'faces/'\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml') \n",
    "eyes_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(id):\n",
    "    return [DATA_FOLDER + id + '/' + f for f in os.listdir(DATA_FOLDER + id) if f.endswith('.jpg')]\n",
    "\n",
    "image_paths = [get_image_paths(str(i).zfill(2)) for i in range(100)]\n",
    "\n",
    "image_paths = np.concatenate(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "if os.path.exists('images.pkl'):\n",
    "  images = pickle.load(open('images.pkl', 'rb'))\n",
    "\n",
    "else:\n",
    "  for image_path in tqdm(image_paths):\n",
    "    images.append(plt.imread(image_path))\n",
    "  pickle.dump(images, open('images.pkl', 'wb'))\n",
    "\n",
    "# images = [plt.imread(image_paths[i]) for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:10<00:00, 46.94it/s]\n"
     ]
    }
   ],
   "source": [
    "def detect_face(frame):\n",
    "    frame_current = frame.copy()\n",
    "    frame_gray = frame_current\n",
    "    \n",
    "    shape_len = len(frame_current.shape)\n",
    "\n",
    "    if shape_len == 3:\n",
    "        frame_gray = cv2.cvtColor(frame_current, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    frame_gray = cv2.equalizeHist(frame_gray)\n",
    "    #-- Detect faces\n",
    "    faces = face_cascade.detectMultiScale(frame_gray)\n",
    "    # detect eyes\n",
    "    eyes = eyes_cascade.detectMultiScale(frame_gray)\n",
    "    # check if there are any faces\n",
    "    if len(faces) == 0:\n",
    "        return []\n",
    "    \n",
    "    if len(eyes) != 2:\n",
    "        return []\n",
    "    \n",
    "    # Check if the line between eyes centers is horizontal (+-5 deg)\n",
    "    eye_centers = []\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        eye_centers.append((ex + ew//2, ey + eh//2))\n",
    "\n",
    "    eye_center1 = eye_centers[0]\n",
    "    eye_center2 = eye_centers[1]\n",
    "\n",
    "    dy = eye_center2[1] - eye_center1[1]\n",
    "    dx = eye_center2[0] - eye_center1[0]\n",
    "    angle = np.arctan2(dy, dx) * 180.0 / np.pi\n",
    "\n",
    "    if abs(angle) > 5:\n",
    "        return []\n",
    "    \n",
    "    return faces\n",
    "\n",
    "image_faces = []\n",
    "\n",
    "for image in tqdm(images):\n",
    "    image_faces.append(detect_face(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 501111.59it/s]\n"
     ]
    }
   ],
   "source": [
    "cropped_faces = []\n",
    "\n",
    "for i, image in enumerate(tqdm(images)):\n",
    "    if len(image_faces[i]) == 0:\n",
    "        continue\n",
    "    \n",
    "    for (x, y, w, h) in image_faces[i]:        \n",
    "        cropped_faces.append(image[y:y + h, x:x + w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 680.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, face in enumerate(tqdm(cropped_faces)):\n",
    "    cv2.imwrite(FACES_FOLDER + image_paths[i].split('/')[-1], cv2.cvtColor(face, cv2.COLOR_RGB2BGR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
